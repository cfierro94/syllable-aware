{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_CLASS.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "132JswBZ5eLl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Install Keras"
      ]
    },
    {
      "metadata": {
        "id": "6WRzJQJu5Jm8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 3
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "3a392c1c-60ea-4264-f359-e2b5513e2bd2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1519178497250,
          "user_tz": 180,
          "elapsed": 2462,
          "user": {
            "displayName": "Diego Valenzuela",
            "photoUrl": "//lh6.googleusercontent.com/-yC1S3sINJo8/AAAAAAAAAAI/AAAAAAAAAWQ/KjmnqiX4R_0/s50-c-k-no/photo.jpg",
            "userId": "105237571791367820180"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip3 install keras --upgrade"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: keras in /usr/local/lib/python3.6/dist-packages\n",
            "Requirement already up-to-date: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras)\n",
            "Requirement already up-to-date: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras)\n",
            "Requirement already up-to-date: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras)\n",
            "Requirement already up-to-date: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kFBIQUg45h7O",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Clone Github"
      ]
    },
    {
      "metadata": {
        "id": "N7HlTNQK5Nno",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62ff9455-3005-406e-b4ec-ecef12edcaf4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1519178498367,
          "user_tz": 180,
          "elapsed": 1022,
          "user": {
            "displayName": "Diego Valenzuela",
            "photoUrl": "//lh6.googleusercontent.com/-yC1S3sINJo8/AAAAAAAAAAI/AAAAAAAAAWQ/KjmnqiX4R_0/s50-c-k-no/photo.jpg",
            "userId": "105237571791367820180"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "#print(os.getcwd())\n",
        "os.chdir('../content')\n",
        "#os.chdir('../')\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab  syllable-aware\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4vjVjr3N5SlR",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d492142-b56b-4366-9f2d-895fed376656",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1519178500153,
          "user_tz": 180,
          "elapsed": 1263,
          "user": {
            "displayName": "Diego Valenzuela",
            "photoUrl": "//lh6.googleusercontent.com/-yC1S3sINJo8/AAAAAAAAAAI/AAAAAAAAAWQ/KjmnqiX4R_0/s50-c-k-no/photo.jpg",
            "userId": "105237571791367820180"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!rm -R syllable-aware/\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "datalab\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LikelnQZ5Z_H",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 4
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "999157c9-557d-4f12-9a3b-5eab1b00ac7f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1519178501910,
          "user_tz": 180,
          "elapsed": 1552,
          "user": {
            "displayName": "Diego Valenzuela",
            "photoUrl": "//lh6.googleusercontent.com/-yC1S3sINJo8/AAAAAAAAAAI/AAAAAAAAAWQ/KjmnqiX4R_0/s50-c-k-no/photo.jpg",
            "userId": "105237571791367820180"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/nlpchile/syllable-aware.git\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'syllable-aware'...\n",
            "remote: Counting objects: 502, done.\u001b[K\n",
            "remote: Compressing objects: 100% (116/116), done.\u001b[K\n",
            "remote: Total 502 (delta 68), reused 40 (delta 11), pack-reused 375\u001b[K\n",
            "Receiving objects: 100% (502/502), 4.65 MiB | 24.17 MiB/s, done.\n",
            "Resolving deltas: 100% (303/303), done.\n",
            "datalab  syllable-aware\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OjcZQ9tF5bbY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "cf75b392-2e39-43d1-e9b1-5099454295bf",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1519178503045,
          "user_tz": 180,
          "elapsed": 1054,
          "user": {
            "displayName": "Diego Valenzuela",
            "photoUrl": "//lh6.googleusercontent.com/-yC1S3sINJo8/AAAAAAAAAAI/AAAAAAAAAWQ/KjmnqiX4R_0/s50-c-k-no/photo.jpg",
            "userId": "105237571791367820180"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('syllable-aware')\n",
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "calculate_Lmax.py     LSTMclass.ipynb\t\t   README.md\r\n",
            "callback_losswise.py  LSTM.py\t\t\t   separadorSilabas.py\r\n",
            "data\t\t      on_epoch_end AND sample.txt  test_perplexity.py\r\n",
            "generate_percent.py   perplexity.py\t\t   test_tokens_selectors.py\r\n",
            "generators.py\t      process_corpus.py\t\t   token_selectors.py\r\n",
            "kmp.py\t\t      process_text.py\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ORPUAyF75k3_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# lstmClass"
      ]
    },
    {
      "metadata": {
        "id": "Nc7uV_GV5dJf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f24da4f-84ae-491e-82f3-f491b65a0440",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1519178504168,
          "user_tz": 180,
          "elapsed": 828,
          "user": {
            "displayName": "Diego Valenzuela",
            "photoUrl": "//lh6.googleusercontent.com/-yC1S3sINJo8/AAAAAAAAAAI/AAAAAAAAAWQ/KjmnqiX4R_0/s50-c-k-no/photo.jpg",
            "userId": "105237571791367820180"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%%writefile lstmClass.py\n",
        "\n",
        "import keras\n",
        "\n",
        "class Model:\n",
        "  \n",
        "  def __init__(self,\n",
        "               vocab_size,\n",
        "               embedding_dim,\n",
        "               hidden_dim,\n",
        "               input_length,\n",
        "               recurrent_dropout,\n",
        "               dropout,\n",
        "               seed):\n",
        "\n",
        "    self.vocab_size = vocab_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.input_length = input_length\n",
        "    self.recurrent_dropout = recurrent_dropout\n",
        "    self.dropout = dropout\n",
        "    self.seed = seed\n",
        "\n",
        "\n",
        "    self.word_embeddings = keras.layers.Embedding(input_dim = self.vocab_size+1,\n",
        "                                                  output_dim = self.embedding_dim,\n",
        "                                                  input_length = self.input_length,\n",
        "                                                  mask_zero = True)\n",
        "\n",
        "    self.lstm_1 = keras.layers.LSTM(units = self.hidden_dim,\n",
        "                                    recurrent_dropout = self.recurrent_dropout,\n",
        "                                    return_sequences = True,\n",
        "                                    unroll = False,\n",
        "                                    implementation = 2)\n",
        "\n",
        "    self.dropout_1 = keras.layers.Dropout(rate = self.dropout,\n",
        "                                          seed = self.seed)\n",
        "\n",
        "    self.lstm_2 = keras.layers.LSTM(units = self.hidden_dim,\n",
        "                                    recurrent_dropout = self.recurrent_dropout,\n",
        "                                    return_sequences = False,\n",
        "                                    unroll = False,\n",
        "                                    implementation = 2)\n",
        "\n",
        "    self.dense = keras.layers.Dense(units = self.vocab_size,\n",
        "                                    activation = 'softmax')\n",
        "    \n",
        "    \n",
        "    \n",
        "  def build(self, optimizer, metrics):   \n",
        "    \n",
        "    self.optimizer = optimizer    \n",
        "    self.metrics = metrics\n",
        "    \n",
        "    # self.learning_rate = learning_rate # (add to forward)\n",
        "    # self.optimizer = keras.optimizers.RMSprop(lr = self.learning_rate)\n",
        "    \n",
        "    \n",
        "    # Build\n",
        "    \n",
        "    self.model = keras.models.Sequential([self.word_embeddings, self.lstm_1, self.dropout_1, self.lstm_2, self.dense])\n",
        "    \n",
        "    self.summary = self.model.summary()\n",
        "    \n",
        "    self.model.compile(loss = 'categorical_crossentropy',\n",
        "                       optimizer = self.optimizer,\n",
        "                       metrics = self.metrics)\n",
        "    \n",
        "    #return self.model\n",
        "  \n",
        "  \n",
        "  def fit(self, generator, epochs, workers, callbacks):\n",
        "    \n",
        "    self.g = generator # Object/Instance Generator, containing .generator() and .steps_per_epoch\n",
        "    \n",
        "    self.epochs = epochs\n",
        "    self.workers = workers  \n",
        "    self.callbacks = callbacks\n",
        "\n",
        "    self.model.fit_generator(generator = self.g.generator(),\n",
        "                             steps_per_epoch = self.g.steps_per_epoch,\n",
        "                             epochs= self.epochs,\n",
        "                             workers = self.workers,\n",
        "                             callbacks = self.callbacks,\n",
        "                             shuffle = False)\n",
        "    \n",
        "    \n",
        "  def summary(self):\n",
        "    \n",
        "    return self.summary"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing lstmClass.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pNwD6QD85tL0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# preprocessClass"
      ]
    },
    {
      "metadata": {
        "id": "IMleNvpV5sZf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7bb15376-2086-4d00-eab4-b9a19cd3fa7a",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1519178505405,
          "user_tz": 180,
          "elapsed": 778,
          "user": {
            "displayName": "Diego Valenzuela",
            "photoUrl": "//lh6.googleusercontent.com/-yC1S3sINJo8/AAAAAAAAAAI/AAAAAAAAAWQ/KjmnqiX4R_0/s50-c-k-no/photo.jpg",
            "userId": "105237571791367820180"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%%writefile preprocessClass.py\n",
        "\n",
        "from process_text import *\n",
        "\n",
        "\n",
        "class Preprocess:\n",
        "  \n",
        "  def __init__(self,\n",
        "               path_to_file,\n",
        "               quantity_word,\n",
        "               quantity_syllable,\n",
        "               train_size):\n",
        "    \n",
        "    \n",
        "    self.path_to_file = path_to_file\n",
        "    \n",
        "    \n",
        "    self.quantity_word = quantity_word\n",
        "    self.quantity_syllable = quantity_syllable\n",
        "    \n",
        "    \n",
        "    self.corpus = open(self.path_to_file, 'r').read().lower()\n",
        "    \n",
        "    \n",
        "    self.selectors = get_selectors(corpus = self.corpus,\n",
        "                                   quantity_word = self.quantity_word,\n",
        "                                   quantity_syllable = self.quantity_syllable)\n",
        "  \n",
        "  \n",
        "    #\n",
        "    self.tokens = get_processed_text(corpus = self.corpus,\n",
        "                                     selectors = self.selectors)\n",
        "    #\n",
        "    \n",
        "    \n",
        "    self.vocabulary = set(self.tokens)\n",
        "\n",
        "    \n",
        "    self.token_to_index = dict((t, i) for i, t in enumerate(self.vocabulary, 1))\n",
        "    \n",
        "    self.index_to_token = dict((self.token_to_index[t], t) for t in self.vocabulary)\n",
        "    \n",
        "    self.ind_corpus = [self.token_to_index[token] for token in self.tokens] # corpus as indexes\n",
        "    \n",
        "    self.vocabulary_as_index = set(self.ind_corpus) # vocabualry as index\n",
        "    \n",
        "    \n",
        "    # testing proposes: test/train split\n",
        "    \n",
        "    self.train_size = train_size\n",
        "    \n",
        "    len_train = int(len(self.ind_corpus)*self.train_size)\n",
        "    \n",
        "    self.train_set = self.ind_corpus[0:len_train] # indexes\n",
        "    self.test_set = self.ind_corpus[len_train:] # indexes\n",
        "    \n",
        "    self.vocabulary_train = set(self.train_set) # indexes\n",
        "    self.vocabulary_test = set(self.test_set) # indexes"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing preprocessClass.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hXdadzxt5zT9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Test LSTM Class"
      ]
    },
    {
      "metadata": {
        "id": "lUMQLKkA5xaP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 1
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4f0b4a14-e866-4a87-a8bd-d1a89746c33c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1519178506858,
          "user_tz": 180,
          "elapsed": 535,
          "user": {
            "displayName": "Diego Valenzuela",
            "photoUrl": "//lh6.googleusercontent.com/-yC1S3sINJo8/AAAAAAAAAAI/AAAAAAAAAWQ/KjmnqiX4R_0/s50-c-k-no/photo.jpg",
            "userId": "105237571791367820180"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "%%writefile testingClasses.py\n",
        "\n",
        "from lstmClass import*\n",
        "from preprocessClass import *\n",
        "\n",
        "\n",
        "import keras\n",
        "from generators import GeneralGenerator\n",
        "\n",
        "import time\n",
        "\n",
        "\n",
        "path_to_file = 'data/horoscopo_test_overfitting.txt'\n",
        "\n",
        "train_size = 1 #0.8\n",
        "\n",
        "\n",
        "## Hyperparameters\n",
        "\n",
        "k = 1000\n",
        "T = 6*k\n",
        "\n",
        "quantity_word = 50\n",
        "\n",
        "quantity_syllable = T - quantity_word\n",
        "\n",
        "\n",
        "## Preprocessing\n",
        "\n",
        "\n",
        "print('\\n Processing \\n')\n",
        "\n",
        "\n",
        "ti = time.time()\n",
        "\n",
        "obj = Preprocess(path_to_file,\n",
        "                 quantity_word = quantity_word,\n",
        "                 quantity_syllable = quantity_syllable,\n",
        "                 train_size = train_size)\n",
        "\n",
        "tf = time.time()\n",
        "dt = (tf - ti) / 60.0\n",
        "print('\\n Elapsed Time {} \\n'.format(dt))\n",
        "\n",
        "##\n",
        "\n",
        "L = 100\n",
        "\n",
        "Lprima = L # se debe calcular. Lprima = f(L)\n",
        "\n",
        "D = 512\n",
        "\n",
        "recurrent_dropout = 0.3\n",
        "\n",
        "dropout = 0.3\n",
        "\n",
        "seed = 0 # para capa Dropout\n",
        "\n",
        "\n",
        "## Train Generator\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "ind_corpus_train = obj.train_set #\n",
        "\n",
        "#ind_val_tokens = obj.test_set\n",
        "\n",
        "vocabulary = obj.vocabulary_as_index\n",
        "\n",
        "\n",
        "## Fit Model\n",
        "\n",
        "epochs = 100 #300\n",
        "\n",
        "workers = 2\n",
        "\n",
        "# https://keras.io/callbacks/\n",
        "callbacks = []\n",
        "\n",
        "\n",
        "## Model\n",
        "\n",
        "\n",
        "model = Model(vocab_size = len(vocabulary),\n",
        "              embedding_dim = D,\n",
        "              hidden_dim = D,\n",
        "              input_length = Lprima,\n",
        "              recurrent_dropout = recurrent_dropout,\n",
        "              dropout = dropout,\n",
        "              seed = seed)\n",
        "\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "optimizer = 'rmsprop' #'adam'\n",
        "\n",
        "metrics = ['top_k_categorical_accuracy', 'categorical_accuracy']\n",
        "\n",
        "\n",
        "model.build(optimizer = optimizer,\n",
        "            metrics = metrics)\n",
        "\n",
        "\n",
        "train_generator = GeneralGenerator(batch_size = batch_size,\n",
        "                                   ind_tokens = ind_corpus_train,\n",
        "                                   vocabulary = vocabulary,\n",
        "                                   max_len = Lprima)\n",
        "\n",
        "#val_gen = GeneralGenerator(batch_size = batch_size,\n",
        "#                           ind_tokens = ind_val_tokens, #\n",
        "#                           voc = vocabulary,\n",
        "#                           max_len = Lprima)\n",
        "\n",
        "\n",
        "print('\\n Training \\n')\n",
        "\n",
        "ti = time.time()\n",
        "\n",
        "model.fit(generator = train_generator,\n",
        "          epochs = epochs,\n",
        "          workers = workers,\n",
        "          callbacks = callbacks)\n",
        "\n",
        "tf = time.time()\n",
        "dt = (tf - ti) / 60.0\n",
        "print('\\n Elapsed Time {} \\n'.format(dt))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing testingClasses.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5gSQumR-53uP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "output_extras": [
            {
              "item_id": 38
            },
            {
              "item_id": 70
            },
            {
              "item_id": 100
            },
            {
              "item_id": 171
            },
            {
              "item_id": 251
            },
            {
              "item_id": 328
            },
            {
              "item_id": 409
            },
            {
              "item_id": 423
            }
          ],
          "base_uri": "https://localhost:8080/",
          "height": 4205
        },
        "outputId": "0dadf856-15bb-4124-cd71-75c47c9311ce",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1519178800664,
          "user_tz": 180,
          "elapsed": 291483,
          "user": {
            "displayName": "Diego Valenzuela",
            "photoUrl": "//lh6.googleusercontent.com/-yC1S3sINJo8/AAAAAAAAAAI/AAAAAAAAAWQ/KjmnqiX4R_0/s50-c-k-no/photo.jpg",
            "userId": "105237571791367820180"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!python3 testingClasses.py"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n",
            "  from ._conv import register_converters as _register_converters\n",
            "Using TensorFlow backend.\n",
            "\n",
            " Processing \n",
            "\n",
            "\n",
            " Elapsed Time 0.07199687957763672 \n",
            "\n",
            "<bound method Model.summary of <lstmClass.Model object at 0x7fbde0dadef0>>\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 100, 512)          86528     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 100, 512)          2099200   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 100, 512)          0         \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 512)               2099200   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 168)               86184     \n",
            "=================================================================\n",
            "Total params: 4,371,112\n",
            "Trainable params: 4,371,112\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            " Training \n",
            "\n",
            "Epoch 1/100\n",
            "2018-02-21 02:01:58.151026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:898] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2018-02-21 02:01:58.151568: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1208] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "totalMemory: 11.17GiB freeMemory: 11.11GiB\n",
            "2018-02-21 02:01:58.151618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1308] Adding visible gpu devices: 0\n",
            "2018-02-21 02:01:58.410027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:989] Creating TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10774 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "5/5 [==============================] - 4s 864ms/step - loss: 5.1852 - top_k_categorical_accuracy: 0.1625 - categorical_accuracy: 0.0547\n",
            "Epoch 2/100\n",
            "5/5 [==============================] - 3s 559ms/step - loss: 4.5590 - top_k_categorical_accuracy: 0.1719 - categorical_accuracy: 0.0672\n",
            "Epoch 3/100\n",
            "5/5 [==============================] - 3s 567ms/step - loss: 4.5146 - top_k_categorical_accuracy: 0.2312 - categorical_accuracy: 0.0953\n",
            "Epoch 4/100\n",
            "5/5 [==============================] - 3s 559ms/step - loss: 4.4721 - top_k_categorical_accuracy: 0.1922 - categorical_accuracy: 0.0797\n",
            "Epoch 5/100\n",
            "5/5 [==============================] - 3s 567ms/step - loss: 4.3491 - top_k_categorical_accuracy: 0.2406 - categorical_accuracy: 0.0719\n",
            "Epoch 6/100\n",
            "5/5 [==============================] - 3s 565ms/step - loss: 4.3316 - top_k_categorical_accuracy: 0.2359 - categorical_accuracy: 0.0906\n",
            "Epoch 7/100\n",
            "1/5 [=====>........................] - ETA: 2s - loss: 4.3616 - top_k_categorical_accuracy: 0.2266 - categorical_accuracy: 0.1016"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 3s 560ms/step - loss: 4.2210 - top_k_categorical_accuracy: 0.2703 - categorical_accuracy: 0.0813\n",
            "Epoch 8/100\n",
            "5/5 [==============================] - 3s 558ms/step - loss: 4.1139 - top_k_categorical_accuracy: 0.2797 - categorical_accuracy: 0.0938\n",
            "Epoch 9/100\n",
            "5/5 [==============================] - 3s 557ms/step - loss: 3.9724 - top_k_categorical_accuracy: 0.3281 - categorical_accuracy: 0.1000\n",
            "Epoch 10/100\n",
            "5/5 [==============================] - 3s 554ms/step - loss: 3.8738 - top_k_categorical_accuracy: 0.3328 - categorical_accuracy: 0.1078\n",
            "Epoch 11/100\n",
            "5/5 [==============================] - 3s 558ms/step - loss: 3.7198 - top_k_categorical_accuracy: 0.3906 - categorical_accuracy: 0.1031\n",
            "Epoch 12/100\n",
            "5/5 [==============================] - 3s 560ms/step - loss: 3.5133 - top_k_categorical_accuracy: 0.4125 - categorical_accuracy: 0.1484\n",
            "Epoch 13/100\n",
            "5/5 [==============================] - 3s 562ms/step - loss: 3.3636 - top_k_categorical_accuracy: 0.4562 - categorical_accuracy: 0.1453\n",
            "Epoch 14/100\n",
            "5/5 [==============================] - 3s 564ms/step - loss: 3.0750 - top_k_categorical_accuracy: 0.5406 - categorical_accuracy: 0.2063\n",
            "Epoch 15/100\n",
            "5/5 [==============================] - 3s 563ms/step - loss: 3.1728 - top_k_categorical_accuracy: 0.4937 - categorical_accuracy: 0.1516\n",
            "Epoch 16/100\n",
            "5/5 [==============================] - 3s 561ms/step - loss: 2.8432 - top_k_categorical_accuracy: 0.6047 - categorical_accuracy: 0.1969\n",
            "Epoch 17/100\n",
            "5/5 [==============================] - 3s 561ms/step - loss: 2.8354 - top_k_categorical_accuracy: 0.6141 - categorical_accuracy: 0.2063\n",
            "Epoch 18/100\n",
            "5/5 [==============================] - 3s 561ms/step - loss: 2.6796 - top_k_categorical_accuracy: 0.6719 - categorical_accuracy: 0.2078\n",
            "Epoch 19/100\n",
            "5/5 [==============================] - 3s 561ms/step - loss: 2.5710 - top_k_categorical_accuracy: 0.6891 - categorical_accuracy: 0.2328\n",
            "Epoch 20/100\n",
            "5/5 [==============================] - 3s 553ms/step - loss: 2.3492 - top_k_categorical_accuracy: 0.7891 - categorical_accuracy: 0.2781\n",
            "Epoch 21/100\n",
            "5/5 [==============================] - 3s 566ms/step - loss: 2.3359 - top_k_categorical_accuracy: 0.7797 - categorical_accuracy: 0.2891\n",
            "Epoch 22/100\n",
            "3/5 [=================>............] - ETA: 1s - loss: 2.1558 - top_k_categorical_accuracy: 0.8177 - categorical_accuracy: 0.3411"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 3s 561ms/step - loss: 2.1645 - top_k_categorical_accuracy: 0.8109 - categorical_accuracy: 0.3328\n",
            "Epoch 23/100\n",
            "5/5 [==============================] - 3s 566ms/step - loss: 2.0647 - top_k_categorical_accuracy: 0.8469 - categorical_accuracy: 0.3578\n",
            "Epoch 24/100\n",
            "5/5 [==============================] - 3s 561ms/step - loss: 2.0346 - top_k_categorical_accuracy: 0.8500 - categorical_accuracy: 0.3547\n",
            "Epoch 25/100\n",
            "5/5 [==============================] - 3s 557ms/step - loss: 1.8807 - top_k_categorical_accuracy: 0.9047 - categorical_accuracy: 0.3766\n",
            "Epoch 26/100\n",
            "5/5 [==============================] - 3s 565ms/step - loss: 1.8489 - top_k_categorical_accuracy: 0.9203 - categorical_accuracy: 0.3813\n",
            "Epoch 27/100\n",
            "5/5 [==============================] - 3s 557ms/step - loss: 1.7403 - top_k_categorical_accuracy: 0.9406 - categorical_accuracy: 0.4172\n",
            "Epoch 28/100\n",
            "5/5 [==============================] - 3s 557ms/step - loss: 1.6709 - top_k_categorical_accuracy: 0.9313 - categorical_accuracy: 0.4469\n",
            "Epoch 29/100\n",
            "5/5 [==============================] - 3s 566ms/step - loss: 1.5924 - top_k_categorical_accuracy: 0.9578 - categorical_accuracy: 0.4500\n",
            "Epoch 30/100\n",
            "5/5 [==============================] - 3s 554ms/step - loss: 1.5963 - top_k_categorical_accuracy: 0.9547 - categorical_accuracy: 0.4438\n",
            "Epoch 31/100\n",
            "5/5 [==============================] - 3s 562ms/step - loss: 1.5489 - top_k_categorical_accuracy: 0.9625 - categorical_accuracy: 0.4828\n",
            "Epoch 32/100\n",
            "5/5 [==============================] - 3s 570ms/step - loss: 1.3941 - top_k_categorical_accuracy: 0.9766 - categorical_accuracy: 0.5078\n",
            "Epoch 33/100\n",
            "5/5 [==============================] - 3s 556ms/step - loss: 1.3130 - top_k_categorical_accuracy: 0.9859 - categorical_accuracy: 0.5563\n",
            "Epoch 34/100\n",
            "5/5 [==============================] - 3s 561ms/step - loss: 1.3112 - top_k_categorical_accuracy: 0.9828 - categorical_accuracy: 0.5109\n",
            "Epoch 35/100\n",
            "5/5 [==============================] - 3s 559ms/step - loss: 1.2785 - top_k_categorical_accuracy: 0.9922 - categorical_accuracy: 0.5422\n",
            "Epoch 36/100\n",
            "5/5 [==============================] - 3s 563ms/step - loss: 1.1787 - top_k_categorical_accuracy: 0.9922 - categorical_accuracy: 0.6031\n",
            "Epoch 37/100\n",
            "4/5 [=======================>......] - ETA: 0s - loss: 1.1710 - top_k_categorical_accuracy: 0.9941 - categorical_accuracy: 0.6133"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r5/5 [==============================] - 3s 567ms/step - loss: 1.1911 - top_k_categorical_accuracy: 0.9953 - categorical_accuracy: 0.5969\r\n",
            "Epoch 38/100\n",
            "5/5 [==============================] - 3s 568ms/step - loss: 1.0615 - top_k_categorical_accuracy: 0.9953 - categorical_accuracy: 0.6562\n",
            "Epoch 39/100\n",
            "5/5 [==============================] - 3s 555ms/step - loss: 1.0863 - top_k_categorical_accuracy: 0.9969 - categorical_accuracy: 0.6406\n",
            "Epoch 40/100\n",
            "5/5 [==============================] - 3s 561ms/step - loss: 0.9926 - top_k_categorical_accuracy: 0.9984 - categorical_accuracy: 0.6766\n",
            "Epoch 41/100\n",
            "5/5 [==============================] - 3s 561ms/step - loss: 0.9433 - top_k_categorical_accuracy: 0.9953 - categorical_accuracy: 0.6984\n",
            "Epoch 42/100\n",
            "5/5 [==============================] - 3s 555ms/step - loss: 0.9086 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.6859\n",
            "Epoch 43/100\n",
            "5/5 [==============================] - 3s 560ms/step - loss: 0.8841 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.7047\n",
            "Epoch 44/100\n",
            "5/5 [==============================] - 3s 564ms/step - loss: 0.8728 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.7250\n",
            "Epoch 45/100\n",
            "5/5 [==============================] - 3s 561ms/step - loss: 0.8392 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.7188\n",
            "Epoch 46/100\n",
            "5/5 [==============================] - 3s 561ms/step - loss: 0.7884 - top_k_categorical_accuracy: 0.9984 - categorical_accuracy: 0.7453\n",
            "Epoch 47/100\n",
            "5/5 [==============================] - 3s 559ms/step - loss: 0.6770 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.8031\n",
            "Epoch 48/100\n",
            "5/5 [==============================] - 3s 561ms/step - loss: 0.7291 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.7656\n",
            "Epoch 49/100\n",
            "5/5 [==============================] - 3s 562ms/step - loss: 0.6453 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.8078\n",
            "Epoch 50/100\n",
            "5/5 [==============================] - 3s 560ms/step - loss: 0.6242 - top_k_categorical_accuracy: 0.9984 - categorical_accuracy: 0.8094\n",
            "Epoch 51/100\n",
            "5/5 [==============================] - 3s 560ms/step - loss: 0.6495 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.7859\n",
            "Epoch 52/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 3s 563ms/step - loss: 0.5597 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.8422\n",
            "Epoch 53/100\n",
            "5/5 [==============================] - 3s 556ms/step - loss: 0.5485 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.8375\n",
            "Epoch 54/100\n",
            "5/5 [==============================] - 3s 565ms/step - loss: 0.5366 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.8297\n",
            "Epoch 55/100\n",
            "5/5 [==============================] - 3s 563ms/step - loss: 0.5230 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.8563\n",
            "Epoch 56/100\n",
            "5/5 [==============================] - 3s 560ms/step - loss: 0.5281 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.8375\n",
            "Epoch 57/100\n",
            "5/5 [==============================] - 3s 560ms/step - loss: 0.4229 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.8937\n",
            "Epoch 58/100\n",
            "5/5 [==============================] - 3s 564ms/step - loss: 0.4078 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.8812\n",
            "Epoch 59/100\n",
            "5/5 [==============================] - 3s 561ms/step - loss: 0.4304 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.8953\n",
            "Epoch 60/100\n",
            "5/5 [==============================] - 3s 561ms/step - loss: 0.3543 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9203\n",
            "Epoch 61/100\n",
            "5/5 [==============================] - 3s 564ms/step - loss: 0.3561 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9016\n",
            "Epoch 62/100\n",
            "5/5 [==============================] - 3s 555ms/step - loss: 0.4091 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.8672\n",
            "Epoch 63/100\n",
            "5/5 [==============================] - 3s 564ms/step - loss: 0.3565 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9016\n",
            "Epoch 64/100\n",
            "5/5 [==============================] - 3s 563ms/step - loss: 0.2864 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9406\n",
            "Epoch 65/100\n",
            "5/5 [==============================] - 3s 558ms/step - loss: 0.2366 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9609\n",
            "Epoch 66/100\n",
            "5/5 [==============================] - 3s 553ms/step - loss: 0.2964 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9266\n",
            "Epoch 67/100\n",
            "3/5 [=================>............] - ETA: 1s - loss: 0.2313 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9609"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 3s 559ms/step - loss: 0.2620 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9562\n",
            "Epoch 68/100\n",
            "5/5 [==============================] - 3s 561ms/step - loss: 0.2375 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9422\n",
            "Epoch 69/100\n",
            "5/5 [==============================] - 3s 551ms/step - loss: 0.2181 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9516\n",
            "Epoch 70/100\n",
            "5/5 [==============================] - 3s 566ms/step - loss: 0.1979 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9562\n",
            "Epoch 71/100\n",
            "5/5 [==============================] - 3s 566ms/step - loss: 0.2348 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9313\n",
            "Epoch 72/100\n",
            "5/5 [==============================] - 3s 564ms/step - loss: 0.2032 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9500\n",
            "Epoch 73/100\n",
            "5/5 [==============================] - 3s 558ms/step - loss: 0.1571 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9734\n",
            "Epoch 74/100\n",
            "5/5 [==============================] - 3s 558ms/step - loss: 0.1542 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9703\n",
            "Epoch 75/100\n",
            "5/5 [==============================] - 3s 562ms/step - loss: 0.1167 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9922\n",
            "Epoch 76/100\n",
            "5/5 [==============================] - 3s 562ms/step - loss: 0.1348 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9719\n",
            "Epoch 77/100\n",
            "5/5 [==============================] - 3s 564ms/step - loss: 0.1208 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9859\n",
            "Epoch 78/100\n",
            "5/5 [==============================] - 3s 562ms/step - loss: 0.1302 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9781\n",
            "Epoch 79/100\n",
            "5/5 [==============================] - 3s 565ms/step - loss: 0.1311 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9719\n",
            "Epoch 80/100\n",
            "5/5 [==============================] - 3s 564ms/step - loss: 0.1109 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9844\n",
            "Epoch 81/100\n",
            "5/5 [==============================] - 3s 563ms/step - loss: 0.1160 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9750\n",
            "Epoch 82/100\n",
            "5/5 [==============================] - 3s 561ms/step - loss: 0.0826 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9875\n",
            "Epoch 83/100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 3s 554ms/step - loss: 0.0670 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9891\n",
            "Epoch 84/100\n",
            "5/5 [==============================] - 3s 555ms/step - loss: 0.0875 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9844\n",
            "Epoch 85/100\n",
            "5/5 [==============================] - 3s 564ms/step - loss: 0.1028 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9734\n",
            "Epoch 86/100\n",
            "5/5 [==============================] - 3s 556ms/step - loss: 0.0637 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9922\n",
            "Epoch 87/100\n",
            "5/5 [==============================] - 3s 556ms/step - loss: 0.0470 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9969\n",
            "Epoch 88/100\n",
            "5/5 [==============================] - 3s 564ms/step - loss: 0.0655 - top_k_categorical_accuracy: 0.9984 - categorical_accuracy: 0.9859\n",
            "Epoch 89/100\n",
            "5/5 [==============================] - 3s 567ms/step - loss: 0.0869 - top_k_categorical_accuracy: 0.9984 - categorical_accuracy: 0.9859\n",
            "Epoch 90/100\n",
            "5/5 [==============================] - 3s 557ms/step - loss: 0.0643 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9859\n",
            "Epoch 91/100\n",
            "5/5 [==============================] - 3s 560ms/step - loss: 0.0324 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9984\n",
            "Epoch 92/100\n",
            "5/5 [==============================] - 3s 565ms/step - loss: 0.0238 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 1.0000\n",
            "Epoch 93/100\n",
            "5/5 [==============================] - 3s 558ms/step - loss: 0.0301 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9969\n",
            "Epoch 94/100\n",
            "5/5 [==============================] - 3s 563ms/step - loss: 0.0521 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9891\n",
            "Epoch 95/100\n",
            "5/5 [==============================] - 3s 557ms/step - loss: 0.0406 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9938\n",
            "Epoch 96/100\n",
            "5/5 [==============================] - 3s 562ms/step - loss: 0.0332 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9938\n",
            "Epoch 97/100\n",
            "5/5 [==============================] - 3s 556ms/step - loss: 0.0357 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9938\n",
            "Epoch 98/100\n",
            "3/5 [=================>............] - ETA: 1s - loss: 0.0280 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9974"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 3s 561ms/step - loss: 0.0322 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9953\n",
            "Epoch 99/100\n",
            "5/5 [==============================] - 3s 562ms/step - loss: 0.0216 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9969\n",
            "Epoch 100/100\n",
            "5/5 [==============================] - 3s 554ms/step - loss: 0.0351 - top_k_categorical_accuracy: 1.0000 - categorical_accuracy: 0.9953\n",
            "\n",
            " Elapsed Time 4.718350195884705 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vYn7MzBGFLJk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}